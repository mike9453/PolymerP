#!/usr/bin/env python3
"""
éšæ®µ1æ”¹é€²ç‰ˆæœ¬ï¼šçµ„åˆæŒ‡ç´‹ + æ”¹é€²çš„RandomForest
é æœŸæå‡ï¼š3-8% RÂ²
"""

import pandas as pd
from rdkit import Chem
from rdkit.Chem import AllChem, MACCSkeys, RDKFingerprint, Descriptors, rdMolDescriptors
from rdkit.Avalon.pyAvalonTools import GetAvalonFP
from rdkit.Chem.MACCSkeys import GenMACCSKeys
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

print("ğŸš€ éšæ®µ1æ”¹é€²ç‰ˆæœ¬ï¼šçµ„åˆæŒ‡ç´‹ + å„ªåŒ–åƒæ•¸")
print("=" * 50)

# è®€å…¥è³‡æ–™
train = pd.read_csv("./data/train.csv")
test = pd.read_csv("./data/test.csv")

print(f"è¨“ç·´é›†å¤§å°: {train.shape}")
print(f"æ¸¬è©¦é›†å¤§å°: {test.shape}")

# SMILES è½‰ mol
train["mol"] = train["SMILES"].apply(Chem.MolFromSmiles)
test["mol"] = test["SMILES"].apply(Chem.MolFromSmiles)

# æŒ‡ç´‹è¨ˆç®—å‡½æ•¸
def compute_morgan_fp(mol, radius=2, nBits=2048):
    return np.array(AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits))

def compute_maccs_fp(mol):
    return np.array(GenMACCSKeys(mol))

def compute_avalon_fp(mol, nBits=512):
    return np.array(GetAvalonFP(mol, nBits=nBits))

def compute_rdk_fp(mol):
    return np.array(RDKFingerprint(mol))

# æ–°å¢ï¼šåŒ–å­¸æè¿°ç¬¦å‡½æ•¸
def compute_descriptors(mol):
    """è¨ˆç®—é‡è¦çš„åŒ–å­¸æè¿°ç¬¦"""
    desc = []
    desc.append(Descriptors.MolWt(mol))                    # åˆ†å­é‡
    desc.append(Descriptors.MolLogP(mol))                  # ç–æ°´æ€§
    desc.append(rdMolDescriptors.CalcTPSA(mol))            # æ¥µæ€§è¡¨é¢ç©
    desc.append(Descriptors.NumAromaticRings(mol))         # èŠ³é¦™ç’°æ•¸
    desc.append(rdMolDescriptors.CalcFractionCSP3(mol))    # sp3æ¯”ä¾‹
    desc.append(Descriptors.NumRotatableBonds(mol))        # å¯æ—‹è½‰éµ
    desc.append(Descriptors.NumHDonors(mol))               # æ°«éµä¾›é«”
    desc.append(Descriptors.NumHAcceptors(mol))            # æ°«éµå—é«”
    desc.append(mol.GetNumHeavyAtoms())                    # é‡åŸå­æ•¸
    desc.append(Descriptors.NumRings(mol))                 # ç’°æ•¸
    return np.array(desc)

print("\nè¨ˆç®—ç‰¹å¾µ...")

# è¨ˆç®—æ‰€æœ‰æŒ‡ç´‹
fingerprints = {}
fingerprints['Morgan'] = np.array([compute_morgan_fp(mol) for mol in train["mol"]])
fingerprints['MACCS'] = np.array([compute_maccs_fp(mol) for mol in train["mol"]])
fingerprints['Avalon'] = np.array([compute_avalon_fp(mol) for mol in train["mol"]])
fingerprints['RDK'] = np.array([compute_rdk_fp(mol) for mol in train["mol"]])

# æ–°å¢ï¼šè¨ˆç®—åŒ–å­¸æè¿°ç¬¦
descriptors = np.array([compute_descriptors(mol) for mol in train["mol"]])

print(f"Morgan æŒ‡ç´‹: {fingerprints['Morgan'].shape}")
print(f"MACCS æŒ‡ç´‹: {fingerprints['MACCS'].shape}")
print(f"Avalon æŒ‡ç´‹: {fingerprints['Avalon'].shape}")
print(f"RDK æŒ‡ç´‹: {fingerprints['RDK'].shape}")
print(f"åŒ–å­¸æè¿°ç¬¦: {descriptors.shape}")

# ğŸ”¥ æ”¹é€²1ï¼šå‰µå»ºæœ€ä½³çµ„åˆç‰¹å¾µ
def create_feature_combinations():
    """å‰µå»ºä¸åŒçš„ç‰¹å¾µçµ„åˆæ–¹æ¡ˆ"""
    combinations = {}
    
    # æ–¹æ¡ˆ1ï¼šæœ€ä½³å–®ä¸€æŒ‡ç´‹ (åŸºæ–¼ä¹‹å‰çµæœ)
    combinations['Best_Single'] = {
        'Tg': fingerprints['MACCS'],
        'FFV': fingerprints['Morgan'], 
        'Tc': fingerprints['MACCS'],
        'Density': fingerprints['MACCS'],
        'Rg': fingerprints['Morgan']
    }
    
    # æ–¹æ¡ˆ2ï¼šæœ€ä½³é›™æŒ‡ç´‹çµ„åˆ
    morgan_maccs = np.hstack([fingerprints['Morgan'], fingerprints['MACCS']])
    combinations['Morgan_MACCS'] = {
        'Tg': morgan_maccs,
        'FFV': morgan_maccs,
        'Tc': morgan_maccs, 
        'Density': morgan_maccs,
        'Rg': morgan_maccs
    }
    
    # æ–¹æ¡ˆ3ï¼šæŒ‡ç´‹ + æè¿°ç¬¦
    combinations['FP_Descriptors'] = {}
    for target in ['Tg', 'FFV', 'Tc', 'Density', 'Rg']:
        if target in ['FFV', 'Rg']:
            base_fp = fingerprints['Morgan']
        else:
            base_fp = fingerprints['MACCS']
        combinations['FP_Descriptors'][target] = np.hstack([base_fp, descriptors])
    
    return combinations

feature_combinations = create_feature_combinations()

# ğŸ”¥ æ”¹é€²2ï¼šå„ªåŒ–çš„RandomForeståƒæ•¸
improved_models = {
    'Basic_RF': RandomForestRegressor(
        n_estimators=100, 
        random_state=42
    ),
    'Improved_RF': RandomForestRegressor(
        n_estimators=300,        # å¢åŠ æ¨¹æ•¸é‡
        max_depth=20,           # é™åˆ¶æ·±åº¦
        min_samples_split=5,    # åˆ†å‰²æœ€å°æ¨£æœ¬
        min_samples_leaf=2,     # è‘‰ç¯€é»æœ€å°æ¨£æœ¬
        max_features='sqrt',    # éš¨æ©Ÿç‰¹å¾µæ•¸
        bootstrap=True,         # è‡ªåŠ©æ¡æ¨£
        random_state=42,
        n_jobs=-1              # ä¸¦è¡Œè¨ˆç®—
    )
}

# ç›®æ¨™è®Šæ•¸
targets = ["Tg", "FFV", "Tc", "Density", "Rg"]
y_data = train[targets].copy()

print(f"\né–‹å§‹æ¨¡å‹æ¯”è¼ƒ...")
print("=" * 80)

# çµæœå„²å­˜
all_results = []

# æ¸¬è©¦æ‰€æœ‰çµ„åˆ
for combo_name, combo_features in feature_combinations.items():
    print(f"\nğŸ§ª æ¸¬è©¦ç‰¹å¾µçµ„åˆ: {combo_name}")
    print("-" * 50)
    
    for model_name, model in improved_models.items():
        combo_results = {'combination': combo_name, 'model': model_name}
        
        for target in targets:
            # å–å¾—è©²ç›®æ¨™çš„éç©ºæ¨£æœ¬
            mask = y_data[target].notnull()
            y_target = y_data[target][mask]
            X_target = combo_features[target][mask]
            
            # åˆ‡åˆ†è³‡æ–™
            X_tr, X_val, y_tr, y_val = train_test_split(
                X_target, y_target, test_size=0.2, random_state=42
            )
            
            # ç‰¹å¾µæ¨™æº–åŒ–
            scaler = StandardScaler()
            X_tr_scaled = scaler.fit_transform(X_tr)
            X_val_scaled = scaler.transform(X_val)
            
            # è¨“ç·´æ¨¡å‹
            model_copy = model.__class__(**model.get_params())
            model_copy.fit(X_tr_scaled, y_tr)
            
            # é æ¸¬èˆ‡è©•ä¼°
            y_pred = model_copy.predict(X_val_scaled)
            r2 = r2_score(y_val, y_pred)
            
            combo_results[target] = f"{r2:.4f}"
            
        all_results.append(combo_results)
        
        # é¡¯ç¤ºçµæœ
        print(f"{model_name:12s}:", end="")
        for target in targets:
            print(f" {target}={combo_results[target]}", end="")
        print()

# è½‰æ›ç‚ºDataFrameä¸¦å„²å­˜
results_df = pd.DataFrame(all_results)
results_df.to_csv("stage1_improvement_results.csv", index=False)

print(f"\n" + "=" * 80)
print("ğŸ“Š éšæ®µ1æ”¹é€²çµæœæ‘˜è¦")
print("=" * 80)

# æ‰¾å‡ºæ¯å€‹ç›®æ¨™çš„æœ€ä½³çµ„åˆ
print("\nğŸ† æœ€ä½³çµæœæ¯”è¼ƒ:")
print("-" * 50)

# è®€å–åŸå§‹çµæœä½œç‚ºåŸºæº–
baseline_results = {
    'Tg': 0.4573, 'FFV': 0.6520, 'Tc': 0.7046, 
    'Density': 0.7401, 'Rg': 0.6705
}

for target in targets:
    best_result = 0
    best_combo = ""
    best_model = ""
    
    for result in all_results:
        current_r2 = float(result[target])
        if current_r2 > best_result:
            best_result = current_r2
            best_combo = result['combination']
            best_model = result['model']
    
    baseline = baseline_results[target]
    improvement = best_result - baseline
    improvement_pct = (improvement / baseline) * 100
    
    print(f"{target:8s}: {baseline:.4f} â†’ {best_result:.4f} "
          f"(+{improvement:+.4f}, {improvement_pct:+.1f}%) "
          f"[{best_combo}, {best_model}]")

print(f"\nğŸ’¾ è©³ç´°çµæœå·²å„²å­˜è‡³: stage1_improvement_results.csv")
print(f"ğŸ¯ ä¸‹ä¸€æ­¥å»ºè­°: å¦‚æœæ”¹é€²æ•ˆæœè‰¯å¥½ï¼Œå¯ä»¥é€²å…¥éšæ®µ2 (æ·»åŠ æ›´å¤šç®—æ³•)")